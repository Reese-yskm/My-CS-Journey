欢迎来到第十二章！这一章是《算法导论》中**承前启后**的关键。

如果说第十一章的“散列表（哈希表）”追求的是**极速查询**，那么第十二章的“二叉搜索树（BST）”追求的就是**秩序**。哈希表里的数据是一盘散沙，而 BST 里的数据是一个**高度组织化的社会**。

---

# 《算法导论》第十二章：二叉搜索树 (Binary Search Tree)

## 1. 天才的构想：什么是二叉搜索树？

普通的二叉树只是用来存数据的，但**二叉搜索树（BST）**给树定下了一条铁律（BST 性质）：
> **对于树中的任何一个节点 $X$：**
> *   它的**左子树**中所有节点的值，都 **$\le X$** 的值。
> *   它的**右子树**中所有节点的值，都 **$\ge X$** 的值。

**这个性质的伟大之处在于**：它把**“二分查找（Binary Search）”**的思想，固化成了一种树形结构。

---

## 2. 第一个奇迹：中序遍历 (In-order Traversal)

在哈希表里，你想把所有元素按顺序打印出来是不可能的（需要 $O(n \lg n)$ 重新排序）。但在 BST 中，这只需要极其简单的三行递归代码，时间复杂度是 **$O(n)$**。

*   **逻辑**：既然左边小、中间中、右边大。那我就按照 **左 $\rightarrow$ 根 $\rightarrow$ 右** 的顺序打印。
*   **代码直觉**：
    
    ```cpp
    void inorder_tree_walk(Node* x) {
        if (x != nullptr) {
            inorder_tree_walk(x->left);
            cout << x->key << " ";
            inorder_tree_walk(x->right);
        }
    }
    ```
*   **感悟**：这就是**递归**最完美的体现。仅仅依靠结构本身的性质，数据自然而然就排好序了。

---

## 3. 查询操作：顺藤摸瓜 ($O(h)$)

BST 的所有查询操作，时间复杂度都与**树的高度 $h$** 成正比。

### 1. 查找 (Search)
*   想找 $k$？比当前节点小就往左走，大就往右走。直到找到或者走到空节点。

### 2. 最大值和最小值 (Min/Max)
*   **Min**：一直往左走，走到头。
*   **Max**：一直往右走，走到头。

### 3. 前驱与后继 (Predecessor & Successor)
这是一个难点。假设你要找节点 $x$ 的**后继**（即所有比 $x$ 大的节点里，最小的那个）。
*   **天才的逻辑（分两种情况）**：
    1.  **$x$ 有右子树**：后继就是它右子树里的**最小值**（右子树最左边的节点）。
    2.  **$x$ 没有右子树**：说明 $x$ 这棵树已经到顶了。我们需要**往上爬（找父节点）**，直到发现自己是某个父节点的**左孩子**为止。那个父节点就是后继。

---

## 4. 动态操作：插入与删除

### 插入 (Insertion) —— $O(h)$
插入非常简单。新来的节点就像从树根掉下来的一个球：比当前节点小就滚到左边，大就滚到右边，直到掉到树底下的空位上。

### 删除 (Deletion) —— 真正的考验
这是大一期末考试最爱考的题目。删除一个节点 $z$ 分三种情况：

1.  **$z$ 没有孩子（叶子节点）**：最简单，直接删掉，修改它爸爸的指针。
2.  **$z$ 只有一个孩子**：把这个孩子“提拔”上来，顶替 $z$ 的位置。
3.  **$z$ 有两个孩子（最难）**：
    *   **天才的替身术**：如果 $z$ 有两个孩子，直接删会让树散架。我们去找 $z$ 的**后继节点 $y$**（比 $z$ 大一点点的那个数）。
    *   因为 $y$ 是 $z$ 的后继，所以 $y$ **一定没有左孩子**。
    *   我们把 $y$ 的值复制给 $z$，然后把原本的 $y$ 删掉（转化为情况 1 或 2）。

---

## 5. C++ 代码演示 (核心实现)

让我们用 C++ 的指针来实现一棵简单的 BST 以及它的插入和中序遍历。

```cpp
#include <iostream>

using namespace std;

// 1. 定义树节点
struct Node {
    int key;
    Node* left;
    Node* right;
    Node* parent; // 指向父节点，寻找后继时需要用到
    
    Node(int k) : key(k), left(nullptr), right(nullptr), parent(nullptr) {}
};

// 2. 插入操作
void tree_insert(Node*& root, Node* z) {
    Node* y = nullptr; // y 是 z 的未来的父节点
    Node* x = root;    // x 用于从根向下探索
    
    // 找到合适的叶子位置
    while (x != nullptr) {
        y = x;
        if (z->key < x->key) x = x->left;
        else x = x->right;
    }
    
    z->parent = y;
    if (y == nullptr) {
        root = z; // 树原来是空的
    } else if (z->key < y->key) {
        y->left = z;
    } else {
        y->right = z;
    }
}

// 3. 中序遍历 (验证数据是否有序)
void inorder_tree_walk(Node* x) {
    if (x != nullptr) {
        inorder_tree_walk(x->left);
        cout << x->key << " ";
        inorder_tree_walk(x->right);
    }
}

int main() {
    Node* root = nullptr;
    
    // Test: Insert unordered data
    int keys[] = {12, 5, 18, 2, 9, 15, 19, 13, 17};
    cout << "--- Binary Search Tree Test ---" << endl;
    cout << "Inserting keys: ";
    for (int k : keys) {
        cout << k << " ";
        tree_insert(root, new Node(k));
    }
    cout << endl;

    // Magic happens here: In-order traversal
    cout << "In-order traversal: ";
    inorder_tree_walk(root);
    cout << endl;

    return 0;
}
```

---

## 6. 致命的缺陷 (The Achilles' Heel)

看到这里，你可能会觉得 BST 很完美。**但是，它有一个致命的弱点！**

*   **思考**：如果你按顺序插入：`1, 2, 3, 4, 5, 6`。
*   **结果**：所有节点都会挂在右子树上，二叉树退化成了一条**单链表**。
*   **后果**：树的高度 $h = n$。所有原本 $O(h)$ 的操作，全部退化成 $O(n)$。

这说明，**BST 的命运，取决于数据的输入顺序**。

**这就是《算法导论》第十三章（红黑树）存在的意义。** 科学家们不能容忍这种“看运气”的结构，于是设计出了一种能够**自动保持平衡**的树。

`TREE-INSERT` 是二叉搜索树（BST）动态操作的基石。它的逻辑非常直观，就像是一颗小球从树根掉下去，根据“左小右大”的规则，最终落入它该去的那个坑里。

结合《算法导论》的伪代码，我们来深度拆解这个函数。

---

### 1. 核心逻辑：两个指针的“双人舞”

在手写 `TREE-INSERT` 时，最天才也最容易被忽视的细节是：**为什么要用两个指针（`x` 和 `y`）？**

*   **指针 `x`（探路者）**：负责从根节点开始向下冲，寻找那个最终的 `NULL` 位置。
*   **指针 `y`（追随者）**：始终紧跟在 `x` 后面。当 `x` 冲出边界变成 `NULL` 时，`y` 恰好停在 `x` 的父节点位置。

**为什么需要 `y`？**
因为在链式结构中，当你发现 `x == NULL` 时，你已经“掉下悬崖”了，此时你无法直接修改父节点的 `left` 或 `right` 指针。`y` 就是那个帮你拉住绳子、完成最后连接的人。

---

### 2. 步骤拆解（以插入节点 $z$ 为例）

1.  **初始化**：让 `y = NULL`，`x = T.root`。
2.  **寻找位置（while 循环）**：
    *   记录当前位置为 `y`。
    *   如果 `z.key < x.key`，`x` 向左转。
    *   否则，`x` 向右转。
3.  **设置父节点**：当循环结束，`z` 的父亲就确定是 `y` 了。
4.  **最后插入**：
    *   如果 `y == NULL`，说明树是空的，`z` 直接当老大（根节点）。
    *   如果 `z.key < y.key`，把 `z` 挂在 `y` 的左边。
    *   否则，挂在右边。

---

### 3. C++ 代码实现

这里要注意一个 C++ 细节：如果你想在函数内部修改 `root` 的指向（比如插入第一个节点时），你需要传递 **指针的引用** `Node* &root`。

```cpp
void tree_insert(Node* &root, Node* z) {
    Node* y = nullptr; // 后继指针
    Node* x = root;    // 探路指针

    // 第一步：自顶向下找位置
    while (x != nullptr) {
        y = x; // 始终保持 y 是 x 的父节点
        if (z->key < x->key) {
            x = x->left;
        } else {
            x = x->right;
        }
    }

    // 第二步：确定 z 的父节点
    z->parent = y;

    // 第三步：将 z 放入正确的位置
    if (y == nullptr) {
        root = z; // 树是空的，z 成为根节点
    } else if (z->key < y->key) {
        y->left = z;
    } else {
        y->right = z;
    }
}
```

---

### 4. 深度感悟：为什么是迭代而不是递归？

虽然插入也可以写成递归，但《算法导论》偏向于写出上面这种**迭代（while 循环）**版本。

*   **空间效率**：递归版本会占用 $O(h)$ 的栈空间。而迭代版本只需要两个指针，空间复杂度是真正的 **$O(1)$**。
*   **简单性**：对于插入来说，我们只需要找到一条路径走到底，不需要回溯，所以迭代非常自然。



删除（Deletion）是二叉搜索树（BST）中最复杂的操作。如果说插入是“随缘落座”，那么删除就是“伤筋动骨的整容手术”。

为了保证删除后树依然满足 BST 性质（左小右大），科学家们设计了一套非常严密的逻辑。

---

### 1. 核心辅助函数：`TRANSPLANT`（移植）

在删除之前，我们需要一个“提拔”工具。它的作用是：**用一棵子树 $v$ 替换另一棵子树 $u$。**

*   **天才之处**：它只负责改父节点的指针，让 $u$ 的爸爸认 $v$ 当儿子。它不关心 $v$ 自己的孩子是谁。
*   **代码逻辑**：
```cpp
void transplant(Node* &root, Node* u, Node* v) {
    if (u->parent == nullptr) { // u 是根节点
        root = v;
    } else if (u == u->parent->left) { // u 是左孩子
        u->parent->left = v;
    } else { // u 是右孩子
        u->parent->right = v;
    }
    if (v != nullptr) {
        v->parent = u->parent; // 更新 v 的父指针
    }
}
```

---

### 2. 删除逻辑的四种情况（由浅入深）

假设我们要删除节点 $z$：

#### 情况 A：$z$ 没有左孩子
*   **处理**：直接把 $z$ 的右子树提拔上来顶替 $z$。
*   （注：如果 $z$ 是叶子节点，右子树也是 `nullptr`，逻辑同样适用。）

#### 情况 B：$z$ 只有左孩子（没有右孩子）
*   **处理**：直接把 $z$ 的左子树提拔上来顶替 $z$。

#### 情况 C & D：$z$ 有两个孩子（最天才的部分）
由于 $z$ 两边都有人，你不能随便提拔一个。我们需要找到 $z$ 的**后继节点 $y$**（右子树里的最小值）来顶替 $z$。

*   **为什么找后继？** 因为后继是比 $z$ 大的数里最小的，它坐到 $z$ 的位置上，依然能保证左边比它小，右边比它大。
*   **子情况 D**：如果 $y$ 藏在右子树深处：
    1.  先用 $y$ 的右孩子顶替 $y$（把 $y$ 拆出来）。
    2.  让 $y$ 接管 $z$ 的右子树。
    3.  最后执行情况 C。
*   **子情况 C**：如果 $y$ 恰好就是 $z$ 的右孩子：
    1.  用 $y$ 顶替 $z$。
    2.  让 $y$ 接管 $z$ 的左子树。

---

### 3. C++ 代码实现：`TREE-DELETE`

这是全书逻辑最紧密的代码块之一：

```cpp
void tree_delete(Node* &root, Node* z) {
    if (z->left == nullptr) {
        // 情况 A：没有左孩子，用右边顶替
        transplant(root, z, z->right);
    } 
    else if (z->right == nullptr) {
        // 情况 B：没有右孩子，用左边顶替
        transplant(root, z, z->left);
    } 
    else {
        // 情况 C & D：有两个孩子
        Node* y = tree_minimum(z->right); // 寻找后继 y
        
        if (y->parent != z) {
            // 情况 D：y 不是 z 的直接孩子
            transplant(root, y, y->right); // 用 y 的右孩子顶替 y
            y->right = z->right;          // z 的右子树交给 y
            y->right->parent = y;
        }
        
        // 情况 C：用 y 顶替 z
        transplant(root, z, y);
        y->left = z->left;   // z 的左子树交给 y
        y->left->parent = y;
    }
    delete z; // 彻底释放内存
}
```

---

### 4. 💡 助教的深度笔记

#### Q1：为什么双孩子情况下，后继 $y$ 一定没有左孩子？
*   **感悟**：因为 $y$ 是右子树里的**最小值**。如果 $y$ 有左孩子，那左孩子肯定比 $y$ 还小，那 $y$ 就不是最小值了。所以，删除 $y$ 永远只属于“情况 A”或“情况 B”。

#### Q2：删除操作的时间复杂度？
*   **分析**：无论哪种情况，我们都只做了常数次的指针修改，以及一次 `tree_minimum`。所以复杂度依然是 **$O(h)$**（$h$ 为树高）。

#### Q3：删除后的“长相”
*   BST 的删除有个有趣的现象：如果你反复删除再插入，树可能会变得越来越不平衡。这再一次印证了 BST “靠天吃饭”的本性。
